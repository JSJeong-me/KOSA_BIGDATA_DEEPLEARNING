{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/KOSA_BIGDATA_DEEPLEARNING/blob/main/Feature_Engineering/3-xgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qm6v1hDvKo7"
      },
      "source": [
        "### XGBoosting\n",
        "\n",
        "https://nbviewer.jupyter.org/github/jphall663/interpretable_machine_learning_with_python/blob/master/xgboost_pdp_ice.ipynb?flush_cache=trueXGBoosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4Rx2dCAvKo-"
      },
      "outputs": [],
      "source": [
        "import numpy as np                   # array, vector, matrix calculations\n",
        "import pandas as pd                  # DataFrame handling\n",
        "#import shap                          # for consistent, signed variable importance measurements\n",
        "import xgboost as xgb                # gradient boosting machines (GBMs)\n",
        "\n",
        "import matplotlib.pyplot as plt      # plotting\n",
        "pd.options.display.max_columns = 999 # enable display of all columns in notebook\n",
        "\n",
        "# enables display of plots in notebook\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)                # set random seed for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIKn5u_6vKo_"
      },
      "source": [
        "#### Import data and clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0k66zWzvKpA"
      },
      "outputs": [],
      "source": [
        "# import XLS file\n",
        "#path = \"C:/Users/heine/Desktop/credit_cards_dataset.csv\"\n",
        "path = \"./Data_USD.csv\"\n",
        "#data = pd.read_csv(path, skiprows=1) # skip the first row of the spreadsheet\n",
        "data = pd.read_csv(path)\n",
        "#path = 'C:\\\\Users\\\\User\\\\Desktop\\\\data\\\\original_data.csv'\\\n",
        "# remove spaces from target column name \n",
        "data = data.rename(columns={'default payment next month': 'DEFAULT_NEXT_MONTH'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K275xeQvKpA"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETLy7XIEvKpB"
      },
      "outputs": [],
      "source": [
        "data['ID']=np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iPQDrp0vKpB"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRc7R0HOvKpC"
      },
      "outputs": [],
      "source": [
        "for i in range(0,30000):\n",
        "    data.loc[i,['ID']]=i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR4uJMMavKpC"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_QUYtvTvKpD"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTzvO1LMvKpD"
      },
      "outputs": [],
      "source": [
        "data.ID = np.array('index0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz298fyNvKpD"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbgv66fKvKpD"
      },
      "outputs": [],
      "source": [
        "# assign target and inputs for GBM\n",
        "#y = 'DEFAULT_NEXT_MONTH'\n",
        "#y='default.payment.next.month'\n",
        "y='DEFAULT_PAYMENT_NEXT_MO'\n",
        "X = [name for name in data.columns if name not in [y, 'ID']]\n",
        "print('y =', y)\n",
        "print('X =', X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcOtJawZvKpE"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtRFn1KnvKpE"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzal-HjEvKpE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s-NyiitvKpE"
      },
      "outputs": [],
      "source": [
        "data[X + [y]].describe() # display descriptive statistics for all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-eV8FJvKpF"
      },
      "outputs": [],
      "source": [
        "# displays last column of Pearson correlation matrix as Pandas DataFrame\n",
        "pd.DataFrame(data[X + [y]].corr()[y]).iloc[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkBaqPFWvKpF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T30zvUV5vKpF"
      },
      "outputs": [],
      "source": [
        "# creates a tuple in which positive correlation values are assigned a 1\n",
        "# and negative correlation values are assigned a -1\n",
        "mono_constraints = tuple([int(i) for i in np.sign(data[X + [y]].corr()[y].values[:-1])])\n",
        "\n",
        "# (-1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuSFxFdVvKpF"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42) # set random seed for reproducibility\n",
        "split_ratio = 0.7     # 70%/30% train/test split\n",
        "\n",
        "# execute split\n",
        "split = np.random.rand(len(data)) < split_ratio\n",
        "train = data[split]\n",
        "test = data[~split]\n",
        "\n",
        "# summarize split\n",
        "print('Train data rows = %d, columns = %d' % (train.shape[0], train.shape[1]))\n",
        "print('Test data rows = %d, columns = %d' % (test.shape[0], test.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdTaE7BRvKpG"
      },
      "source": [
        "### Setting Parameter\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_intro.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR8_Bn6CvKpG"
      },
      "outputs": [],
      "source": [
        "# XGBoost uses SVMLight data structure, not Numpy arrays or Pandas DataFrames \n",
        "dtrain = xgb.DMatrix(train[X], train[y])\n",
        "dtest = xgb.DMatrix(test[X], test[y])\n",
        "\n",
        "# used to calibrate predictions to mean of y\n",
        "base_y = train[y].mean()\n",
        "\n",
        "# tuning parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',             # produces 0-1 probabilities for binary classification\n",
        "    'booster': 'gbtree',                        # base learner will be decision tree\n",
        "    'eval_metric': 'auc',                       # stop training based on maximum AUC, AUC always between 0-1\n",
        "    'eta': 0.08,                                # learning rate\n",
        "    'subsample': 0.9,                           # use 90% of rows in each decision tree\n",
        "    'colsample_bytree': 0.9,                    # use 90% of columns in each decision tree\n",
        "    'max_depth': 15,                            # allow decision trees to grow to depth of 15\n",
        "    'monotone_constraints':mono_constraints,    # 1 = increasing relationship, -1 = decreasing relationship\n",
        "    'base_score': base_y,                       # calibrate predictions to mean of y \n",
        "    'seed': 42                               # set random seed for reproducibility\n",
        "}\n",
        "\n",
        "# watchlist is used for early stopping\n",
        "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "# train model\n",
        "xgb_model = xgb.train(params,                   # set tuning parameters from above                   \n",
        "                      dtrain,                   # training data\n",
        "                      1000,                     # maximum of 1000 iterations (trees)\n",
        "                      evals=watchlist,          # use watchlist for early stopping \n",
        "                      early_stopping_rounds=50, # stop after 50 iterations (trees) without increase in AUC\n",
        "                      verbose_eval=True)        # display iteration progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5dlhZS-vKpG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaNI6RiqvKpH"
      },
      "outputs": [],
      "source": [
        "# dtest is DMatrix\n",
        "# shap_values is Numpy array\n",
        "shap_values = xgb_model.predict(dtest, pred_contribs=True, ntree_limit=xgb_model.best_ntree_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O39mFZJkvKpH"
      },
      "outputs": [],
      "source": [
        "ypred=xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5UdDhyuvKpH"
      },
      "outputs": [],
      "source": [
        "ypred.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGU8XYg_vKpH"
      },
      "outputs": [],
      "source": [
        "predictions = np.array([round(value) for value in ypred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqlKTpjOvKpH"
      },
      "outputs": [],
      "source": [
        "predictions.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Zqh7APvKpH"
      },
      "outputs": [],
      "source": [
        "ypred.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXNomzhXvKpH"
      },
      "outputs": [],
      "source": [
        "#xgb_model.predict(dtest, pred_contribs=True, ntree_limit=xgb_model.best_ntree_limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfRrvm_JvKpI"
      },
      "outputs": [],
      "source": [
        "shap_values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1MLRkWCvKpI"
      },
      "outputs": [],
      "source": [
        "#test['DEFAULT_PAYMENT_NEXT_MO']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1_leGHNvKpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "accuracy = accuracy_score(test[y], predictions)\n",
        "cm = confusion_matrix(test[y], predictions)\n",
        "precision = precision_score(test[y], predictions)\n",
        "recall = recall_score(test[y], predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVHVvRWWvKpI"
      },
      "outputs": [],
      "source": [
        "print(accuracy)\n",
        "print(cm)\n",
        "print(precision)\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwh1LZUMvKpI"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo9pgeR1vKpJ"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plot_confusion_matrix(cm, classes=['Non_Default','Default'], normalize=False,\n",
        "                      title='Non Normalized confusion matrix')\n",
        "#plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python Multi",
      "language": "python",
      "name": "multi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "12-2xgb.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}