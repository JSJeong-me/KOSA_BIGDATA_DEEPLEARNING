{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/KOSA_BIGDATA_DEEPLEARNING/blob/main/stable-diffusion-LORA_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A notebook for finetuning Stable Diffusion using LORA.\n",
        "\n",
        "Tested with [Stable Diffusion v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5).\n",
        "\n",
        "Notebook developed by [pedrogengo](https://github.com/pedrogengo)."
      ],
      "metadata": {
        "id": "EZH8PmZoncOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "-n_lr2oaTB58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKq5g6Inaq1g"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloneofsimo/lora.git && sed -i 's/functools.cache/functools.lru_cache(maxsize=None)/g' /content/lora/lora_diffusion/xformers_utils.py && pip install /content/lora\n",
        "!pip install accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "d9gKhQjMTEQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "\n",
        "PRETRAINED_MODEL=\"runwayml/stable-diffusion-v1-5\" #@param{type: 'string'}\n",
        "PROMPT=\"ktn\" #@param{type: 'string'}\n",
        "\n",
        "OUTPUT_DIR=\"./\" #@param{type: 'string'}\n",
        "IMAGES_FOLDER_OPTIONAL=\"./images\" #@param{type: 'string'}\n",
        "\n",
        "RESOLUTION=\"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "RESOLUTION=int(RESOLUTION)\n",
        "\n",
        "if PRETRAINED_MODEL == \"\":\n",
        "  print('\u001b[1;31mYou should define the pretrained model.')\n",
        "\n",
        "else:\n",
        "  if IMAGES_FOLDER_OPTIONAL==\"\":\n",
        "    INSTANCE_DIR = \"/content/data_example\"\n",
        "    if not os.path.exists(str(INSTANCE_DIR)):\n",
        "      %mkdir -p \"$INSTANCE_DIR\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "        shutil.move(filename, INSTANCE_DIR)\n",
        "  else:\n",
        "    INSTANCE_DIR = IMAGES_FOLDER_OPTIONAL\n",
        "\n",
        "  if OUTPUT_DIR == \"\":\n",
        "    OUTPUT_DIR = \"/content/output\"\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    %mkdir -p \"$OUTPUT_DIR\""
      ],
      "metadata": {
        "id": "RXhqKsN8cEop",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS = 300 #@param {type:\"slider\", min:0, max:10000, step:10}\n",
        "BATCH_SIZE = 1 #@param {type:\"slider\", min:0, max:128, step:1}\n",
        "FP_16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ----\n",
        "#@markdown UNET PARAMS\n",
        "LEARNING_RATE = 3e-4 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ----\n",
        "TRAIN_TEXT_ENCODER = True #@param {type:\"boolean\"}\n",
        "#@markdown TEXT ENCODER PARAMS\n",
        "LEARNING_RATE_TEXT_ENCODER = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "NEW_LEARNING_RATE = LEARNING_RATE / BATCH_SIZE\n",
        "NEW_LEARNING_RATE_TEXT_ENCODER = LEARNING_RATE_TEXT_ENCODER / BATCH_SIZE\n",
        "\n",
        "if FP_16:\n",
        "  fp_16_arg = \"fp16\"\n",
        "else:\n",
        "  fp_16_arg = \"no\"\n",
        "\n",
        "if TRAIN_TEXT_ENCODER:\n",
        "  command = (f'accelerate launch lora/training_scripts/train_lora_dreambooth.py '\n",
        "             f'--pretrained_model_name_or_path=\"{PRETRAINED_MODEL}\" '\n",
        "             f'--instance_data_dir=\"{INSTANCE_DIR}\" '\n",
        "             f'--output_dir=\"{OUTPUT_DIR}\" '\n",
        "             f'--instance_prompt=\"{PROMPT}\" '\n",
        "             f'--resolution=512 '\n",
        "             f'--use_8bit_adam '\n",
        "             f'--mixed_precision=\"{fp_16_arg}\" '\n",
        "             f'--train_batch_size=1 '\n",
        "             f'--gradient_accumulation_steps=1 '\n",
        "             f'--learning_rate={NEW_LEARNING_RATE} '\n",
        "             f'--lr_scheduler=\"constant\" '\n",
        "             f'--lr_warmup_steps=0 '\n",
        "             f'--max_train_steps={STEPS} '\n",
        "             f'--train_text_encoder '\n",
        "             f'--lora_rank=16 '\n",
        "             f'--learning_rate_text={NEW_LEARNING_RATE_TEXT_ENCODER}')\n",
        "else:\n",
        "  command = (f'accelerate launch lora/training_scripts/train_lora_dreambooth.py '\n",
        "             f'--pretrained_model_name_or_path=\"{PRETRAINED_MODEL}\" '\n",
        "             f'--instance_data_dir=\"{INSTANCE_DIR}\" '\n",
        "             f'--output_dir=\"{OUTPUT_DIR}\" '\n",
        "             f'--instance_prompt=\"{PROMPT}\" '\n",
        "             f'--resolution=512 '\n",
        "             f'--use_8bit_adam '\n",
        "             f'--mixed_precision=\"{fp_16_arg}\" '\n",
        "             f'--train_batch_size=1 '\n",
        "             f'--gradient_accumulation_steps=1 '\n",
        "             f'--learning_rate={NEW_LEARNING_RATE} '\n",
        "             f'--lr_scheduler=\"constant\" '\n",
        "             f'--lr_warmup_steps=0 '\n",
        "             f'--lora_rank=16 '\n",
        "             f'--max_train_steps={STEPS} '\n",
        "             f'--learning_rate_text={NEW_LEARNING_RATE_TEXT_ENCODER}')\n",
        "!rm -rf $INSTANCE_DIR/.ipynb_checkpoints\n",
        "!{command}"
      ],
      "metadata": {
        "id": "ZDMXQnKfat1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "-DkyZBDBTPKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LOADING MODEL AND MONKEY PATCHING IT\n",
        "import torch\n",
        "from lora_diffusion import monkeypatch_or_replace_lora, tune_lora_scale\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(PRETRAINED_MODEL, torch_dtype=torch.float16).to(\"cuda\")\n",
        "monkeypatch_or_replace_lora(pipe.unet, torch.load(os.path.join(OUTPUT_DIR, \"lora_weight.pt\")))\n",
        "monkeypatch_or_replace_lora(pipe.text_encoder, torch.load(os.path.join(OUTPUT_DIR, \"lora_weight.text_encoder.pt\")), target_replace_module=[\"CLIPAttention\"])"
      ],
      "metadata": {
        "id": "IDArwYibSaB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.safety_checker = None"
      ],
      "metadata": {
        "id": "CLV5oR3BBW69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INFERENCE_PROMPT = 'heart' #@param {type:\"string\"}\n",
        "LORA_SCALE_UNET = 0.1 #@param {type:\"number\"}\n",
        "LORA_SCALE_TEXT_ENCODER = 0.1 #@param {type:\"number\"}\n",
        "GUIDANCE = 1.4 #@param {type:\"slider\", min:0, max:15, step:0.2}\n",
        "tune_lora_scale(pipe.unet, LORA_SCALE_UNET)\n",
        "if TRAIN_TEXT_ENCODER:\n",
        "  tune_lora_scale(pipe.text_encoder, LORA_SCALE_TEXT_ENCODER)\n",
        "image = pipe(INFERENCE_PROMPT, num_inference_steps=50, guidance_scale=GUIDANCE).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "uy27Q47sa-ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Gfg7tbW58_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}